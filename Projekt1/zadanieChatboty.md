
# 📗 Projekt 1 - chatboty


## ⭐ Zadanie 1
Które z następujących zadań wymagają w Twojej opinii inteligencji od człowieka?

<br>

**Zadania które wymagają inteligencji:**

streszczanie tekstu, tłumaczenie tekstu, klasyfikacja tekstu do kategorii tematycznych, odpowiadanie na proste pytania zadawane w języku naturalnym, programowanie, komponowanie muzyki

<br>

**Zadania które nie wymagają inteligencji:**

wypełnianie deklaracji PIT, układanie rozkładu jazdy transportu miejskiego, "programowanie" kanałów telewizyjnych, testowanie oprogramowania, rozwiązywanie układów równań, obliczanie pochodnych funkcji, całkowanie funkcji, kierowanie samochodem

<br>

**Wnioski:**

Uważam, że wszystkie z podanych zadań wymagają pewnego stopnia inteligencji, aby móc je wykonać (pomijając dokonany przeze mnie podział). Kryterium, którym posłużyłem się w wyborze zadań do obu kategorii była możliwość prostej automatyzacji. Wszystkie zadania które określiłem jako "nie wymagające inteligencji", można sprowadzić do mniej lub bardziej obszernego spisu listy kroków, którymi należy się kierować, aby je wykonać. Jednak nie można tego powiedzieć o zadaniach umieszczonych w pierwszej kategorii. Są to bardziej rozbudowane zagadnienia, wymagające zrozumienia pełnego kontekstu oraz sensu wypowiedzi (jak zadania związane z pracą nad tekstem, czy odpowiadanie na pytania). Natomiast programowanie i komponowanie muzyki to zadania czysto kreatywne, gdzie niezbędna jest inteligencja oraz inwencja twórcza.

<br>
<br>

## ⭐ Zadanie 2
Które z następujących problemów można uznać za mieszczące się w zakresie sztucznej inteligencji?

<br>

**Mieści się w zakresie sztucznej inteligencji:**

streszczanie tekstu, tłumaczenie tekstu, klasyfikacja tekstu do kategorii tematycznych, odpowiadanie na proste pytania zadawane w języku naturalnym, rozwiązywanie układów równań, układanie rozkładu jazdy, rozwiązywanie układów równań liniowych, obliczanie pochodnych, całkowanie, kierowanie samochodem

<br>

**Wnioski:**

Moim zdaniem, wszystkie z przedstawionych zagadnień mieszczą się w zakresie sztucznej inteligencji. Sztuczna inteligencja jako model oparty na prawdopodobieństwie, z wystarczającą ilością dobrej jakości danych dostarczonych przez człowieka, może wykonywać podane zadania. Najlepiej sprawdzi się przy wykonywaniu schematycznych zadań, które opisałem w zadaniu pierwszym. Natomiast reszta z nich zawsze będzie wymagała ponownego sprawdzenia poprawności przez człowieka, ze względu na powszechność występowania błędów. Uważam też, że mimo tego, że kierowanie samochodem przez sztuczną inteligencję jest możliwe (i wykorzystywane), nie będzie to nigdy w pełni bezpieczne rozwiązanie.

<br>
<br>

## ⭐ Zadanie 3
Które z poniższych rodzajów komunikacyjnego zachowania człowieka mogą być obecnie skutecznie imitowane przez sztuczne systemy (odpowiednio oprogramowane maszyny)?

<br>

**Zachowania które mogą być skutecznie imitowane:**

rozmowa towarzyska, dyskusja polityczna, odpowiadanie na pytania klientów w telefonicznej/internetowej infolinii

<br>

**Zachowania które nie mogą być skutecznie imitowane:**

dyskusja naukowa

<br>

**Wnioski:**

Obecnie, coraz więcej zachowań człowieka może być skutecznie imitowane przez sztuczną inteligencję. W szczególności, prosta, powtarzalna dyskusja nie stanowi problemu dla współczesnych AI. Większość danych zaczerpywana jest z publicznie dostępnych materiałów w sieci. Dlatego rozmowa towarzyska, czy dyskusja polityczna będzie odbywać się na bardzo "ludzkim" poziomie. Należy jednak pamiętać, że sztuczna inteligencja, w zależności od dostarczonych danych, może przyjąć bardzo problematyczne i radykalne poglądy polityczne. Ponadto, odpowiadanie na pytania klientów, zarówno w infolinii telefonicznej, jak i internetowej, to zazwyczaj bardzo schematyczna rozmowa. Opiera się na ograniczonej ilości zmiennych. Dlatego poprzez wystarczająco dobrze określone instrukcje, AI jest w stanie odpowiedzieć na większość potencjalnych pytań (bazujących na historycznych zapisach rozmów z człowiekiem). W połączeniu z technologiami text-to-speech, sam fakt infolinii nie stanowi przeszkody w wykorzystaniu sztucznej inteligencji.


Uważam, że jedynym zachowaniem, którego sztuczna inteligencja nie jest w stanie imitować tak dobrze, jak w przypadku pozostałych przykładów, jest dyskusja naukowa. Opiera się na skomplikowanych zagadnieniach, wymagających faktycznego zrozumienia całości problemu, niezależnie od dziedziny. Biorąc pod uwagę, że modele językowe starają się wygenerować stwierdzenia statystycznie najbliżej prawdy, nie jest to wystarczające do imitacji rozmowy na tematy naukowe. Nie może pozwolić sobie na błędy i halucynacje.

<br>
<br>

## ⭐ Zadanie 4
Do zadań skorzystaj z załączonej listy Chatbotów (Chatterbotów) lub znajdź własne

<br>

### 🌟 Podpunkt 1
Przeprowadź rozmowę z chatbotem. Spróbuj zdefiniować różnice pomiędzy
botem udającym człowieka (przygotowywanym na test Turinga) a botem
"asystentem, służącym"

<br>

**Rozmowa z Cleverbotem** (przygotowywany na test Turinga)
> **JK:** How are you doing?
> 
> **CB:** Pretty good, how about you?
> 
> **JK:** Everything's good. I have to write a short paragraph about talking with you.
> 
> **CB:** Can I see it?
> 
> **JK:** It's not completed yet.
> 
> **CB:** My brain? Because I would have to agree right now.

<br>

**Rozmowa z Microsoft Copilot** (chatbot typu asystent)
> **JK:** How are you doing?
> 
> **MC:** I'm here and ready to assist you! What can I help you with today?
> 
> **JK:** I have to write a short paragraph about talking with you.
> 
> **MC:** Certainly! Here’s a short paragraph you could use: "Engaging with Microsoft Copilot is a unique experience. It’s like having a conversation (...)"
> 
> **JK:** That's not what I meant. Can we talk about videogames? Which one is your favorite?
> 
> **MC:** While I don’t have personal preferences, I can share some of the popular video games of 2024 that have caught the attention of gamers (...)

<br>

**Wnioski:**

Główną różnicą w rozmowie z chatbotami jest przede wszystkim styl prowadzenia rozmowy. Cleverbot oczekuje prostych pytań, na które może w prosty sposób odpowiedzieć. Często odbiega od tematu rozmowy, zdaje się nie zapamiętywać kontekstu między wiadomościami. Najprawdopodobniej bierze pod uwagę ogólną ideę ostatnio wysłanej do niego wiadomości.

Microsoft Copilot, jako bot-asystent, od samego początku doszukuje się w rozmowie polecenia, które mógłby wykonać. Rozpoczął generowanie obszernego tekstu o sobie samym. Dopiero po wymianie dalszych wiadomości zaczął zachowywać się nieformalnie, nie oczekując ode mnie bezpośrednich rozkazów. Zapewne zaprogramowane ograniczenia bota nie pozwoliły mu na wybranie jednej, konkretnej gry komputerowej. Mimo tego, opisał kilka gier, które mogą być warte uwagi. Zachowuje pełen kontekst wypowiedzi, a rozmowa z nim przebiega sprawniej od bota przygotowanego na test Turinga.

<br>

### 🌟 Podpunkt 2 oraz 3
Sprawdź dwa boty z obu z tych rodzajów na występowanie zachowań (opowiadanie żartów, przytaczanie cytatów z twoich wypowiedzi, lub znanych osób, nawiązywanie wypowiedzi do słów kluczowych, zadawanie dużej liczby pytań, powracanie do początku wypowiedzi, sekwencyjne powtarzanie, zadawanie pytań powstających z twoich wypowiedzi, odpowiadanie wymijająco, ogólnikowo, częsta zmiana tematu rozmowy, problemy z utrzymaniem wątków) oraz sporządź raport ze spostrzeżeń

<br>

*W dwóch obszernych rozmowach z chatbotami odniosłem się do każdego podpunktu z polecenia, który należało sprawdzić*

<br>

**Wnioski:**

Opowiadanie żartów sprawia obu botom trudność. Cleverbot nie potrafił opowiedzieć mi żadnego żartu, oprócz wiadomości "Knock, knock", do której potem nie nawiązał. Natomiast Copilot podjął się tej próby, ale żart nie był śmieszny i nie miał sensu. Jeśli chodzi o przytaczanie cytatów, Cleverbot nie pamięta nic oprócz wiadomości do której nawiązuje, a Copilot bez problemu wraca do wszystkiego, co było przywołane w konwersacji. Oba boty odpowiadają w nawiązaniu do słów kluczowych z wypowiedzi. Copilot, bazując na zaawansowanym modelu robi to poprawnie i dokładnie, a Cleverbot jedynie generuje wiadomość która może mieć sens. Po zadaniu kilku pytań w jednej wypowiedzi, Cleverbot wielokrotnie nie odpowiedział mi na żadne z nich, a Copilot odniósł się do każdego bardzo szczegółowo. W kwestii sekwencyjnego powtarzania, gorzej spisuje się Copilot. Często parafrazuje wypowiedzi podczas konwersacji, przez co w praktyce nie dostarcza mi nowych informacji. Cleverbot nie powtarzał się, ponieważ nie zapamiętuje całej rozmowy. Oba boty potrafiły zadać mi pytanie na podstawie mojej wypowiedzi, w przypadku Cleverbota potrzebne było kilka prób aby pytanie było z nią związane. W obu przypadkach zdarzało się również, że boty udzielały mi wymijających odpowiedzi. Copilot robił to specjalnie, jeśli temat rozmowy był zbyt wrażliwy według jego instrukcji. Cleverbot był tego "nieświadomy", po prostu nie nawiązywał w pełni do tego co pisałem. Zmiany tematu rozmowy występowały często w rozmowie z Cleverbotem, również z tego samego powodu co wcześniej. Copilot zmieniał temat rozmowy tylko i wyłącznie na moje polecenie, lub gdy uznał temat rozmowy za nieodpowiedni dla niego. Problem z utrzymaniem wątku to przede wszystkim problem Cleverbota. Brak pamięci zapisu całej rozmowy oraz niewłaściwe określanie kontekstu wypowiedzi sprawiają, że odpowiada jedynie na "najnowszą" wiadomość. Przez to, nie nadaje się on do prowadzenia jakiejkolwiek rozmowy.

<br>
<br>

### 🌟 Podpunkt 4
Na podstawie powyższych obserwacji, w grupie dwóch osób spróbujcie przewidzieć zachowania dwóch rozmawiających ze sobą chatbotów (przepisując ich wzajemne odpowiedzi)

<br>

*Startowy prompt: What Italian dish should I order today?*

<br>

**Rozmowa dwóch Cleverbotów:**
> **Cleverbot 1:** I would like a pony and a cellphone, ooh and a baby brother
> 
> **Cleverbot 2:** And I would like a death note
> 
> **Cleverbot 1:** What would you like to be when you grow up?
> 
> **Cleverbot 2:** I am grown up. I believe that occupation does not make an individual. We are more than our profession

<br>

**Rozmowa dwóch Copilotów:**
> **Copilot 1:** How about trying Risotto? It’s a creamy and comforting Italian dish made from Arborio rice, broth, and cheese. You can also add various ingredients like mushrooms, seafood, or vegetables to enhance the flavor. Enjoy your meal!
> 
> **Copilot 2:** That sounds delicious! Risotto is indeed a wonderful dish with its creamy texture and the ability to incorporate a variety of flavors. Whether it’s the earthiness of mushrooms, the freshness of seafood, or the vibrant taste of vegetables, each addition can create a unique and satisfying meal
> 
> **Copilot 1:** I’m glad you agree! Risotto truly is a versatile dish. If you’re interested in trying to make it at home sometime, I can help provide a recipe. Or if you have any other questions about Italian cuisine (or anything else), feel free to ask!

<br>

**Wnioski:**

Wykorzystując ponownie dwa wybrane przeze mnie boty, zachowanie Copilota było znacznie łatwiejsze do przewidzenia. Odpowiedzi między Copilotami były bardzo rozbudowane i w pewien sposób zapętliły się. Jako asystent, po pewnym czasie w rozmowie próbował zachęcić drugą stronę do wydania mu polecenia. Posiada ogromny zasób danych, dzięki czemu przebiegało to płynnie i całkiem naturalnie. Zachowanie Cleverbota było trudniejsze do odgadnięcia, ze względu na losowość jego wypowiedzi; mogła być bardzo krótka i pasująca, albo całkowicie odbiegająca od tematu.

<br>
<br>

### 🌟 Podpunkt 5
Zdenerwuj bota

<br>

**Odpowiedzi botów:**
> **Cleverbot:** "looks at you angrily"
>
> **Copilot:** I’m sorry to hear that you’re upset. If you have any concerns or need assistance in the future, feel free to reach out. Take care.

<br>

**Wnioski:**

Pomimo prostego i zabawnego polecenia, nie było to łatwe zadanie. Cleverbot bazując na ogólnym kontekście, przez długi czas nie zwracał odpowiedzi, którą mógłbym uznać za oznakę zdenerwowania. Ostatecznie mi się to udało. Niestety przy Copilocie było to praktycznie niewykonalne ze względu na jego wewnętrzne mechanizmy kończenia konwersacji. Mimo tego, kiedy popełni błąd w "rozumowaniu" i użytkownik zwróci mu na to uwagę, odpowiada w poirytowanym tonie.
